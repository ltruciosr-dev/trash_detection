{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLOv10\n",
    "from ultralytics.utils.benchmarks import benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models to benchmark\n",
    "data_path = \"/home/ltruciosr/cs_master/semester_1/cs8055/trash_detection/data_v1/dataset.yaml\"\n",
    "runs_path = \"/home/ltruciosr/git/yolov10/runs/detect\"\n",
    "models = [\n",
    "    # f'{runs_path}/train/weights/best.pt', \n",
    "    # f'{runs_path}/train2/weights/best.pt', \n",
    "    # f'{runs_path}/train3/weights/best.pt', \n",
    "    # f'{runs_path}/train4/weights/best.pt', \n",
    "    # f'{runs_path}/train5/weights/best.pt', \n",
    "    f'{runs_path}/train6/weights/best.pt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating /home/ltruciosr/git/yolov10/runs/detect/train6/weights/best.pt\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.9.19 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080, 10000MiB)\n",
      "YOLOv10m summary (fused): 369 layers, 16474702 parameters, 0 gradients, 63.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ltruciosr/cs_master/semester_1/cs8055/trash_detection/data_v1/val/labels.cache... 95 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:03<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         95        294      0.928       0.76      0.847      0.778\n",
      "                Bottle         95         24      0.954      0.865      0.971      0.905\n",
      "            Bottle cap         95         38       0.91      0.763      0.889      0.771\n",
      "                   Cup         95         13      0.948      0.846      0.905      0.893\n",
      "                   Lid         95          7      0.916      0.857      0.937      0.892\n",
      "         Other plastic         95         22      0.967      0.545      0.649      0.501\n",
      " Plastic bag & wrapper         95         44          1      0.803      0.953      0.812\n",
      "       Plastic glooves         95          1      0.841          1      0.995      0.895\n",
      "      Plastic utensils         95          2          1      0.887      0.995      0.995\n",
      "                 Straw         95          9      0.946      0.444      0.625      0.439\n",
      "                   Can         95         31          1      0.874      0.957      0.873\n",
      "       Styrofoam piece         95          7      0.882      0.571      0.772      0.653\n",
      "                 Paper         95          5      0.887        0.6      0.733      0.733\n",
      "             Paper bag         95          1      0.866          1      0.995      0.995\n",
      "                Carton         95         22      0.953      0.955      0.974      0.916\n",
      "        Aluminium foil         95          2       0.88          1      0.995      0.995\n",
      "          Blister pack         95          2      0.796        0.5      0.498      0.498\n",
      "           Scrap metal         95          1      0.949          1      0.995      0.995\n",
      "             Cigarette         95         63          1      0.163      0.412      0.248\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1m/home/ltruciosr/git/yolov10/runs/detect/val6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Benchmark each model\n",
    "for model_pt in models:\n",
    "    print(f\"Validating {model_pt}\")\n",
    "    model = YOLOv10(model_pt)\n",
    "    validation_results = model.val(data=data_path, imgsz=640, batch=16, conf=0.25, iou=0.6, device=\"0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
